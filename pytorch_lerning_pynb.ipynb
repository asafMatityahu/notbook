{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpdPnHHEg7c84a0mT7ox4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asafMatityahu/notbook/blob/main/pytorch_lerning_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import ReLU\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "I6Q6s1VOXVM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparing and loading\n",
        "# Y = a+bX\n",
        "# b = weight\n",
        "# a = bias\n",
        "def known_parameters():\n",
        "    # the Parameters\n",
        "    weight = 0.7\n",
        "    bias = 0.3\n",
        "\n",
        "    # Create data\n",
        "    start = 0\n",
        "    end = 1\n",
        "    step = 0.02\n",
        "    X = torch.arange(start,end,step,device=device)\n",
        "    print(X.ndim)\n",
        "    X = X.unsqueeze(1)\n",
        "    print(X.ndim)\n",
        "    y = weight * X + bias\n",
        "    print(y)\n",
        "\n",
        "    # create traning test set\n",
        "    tranig_split = int(0.8 * len(X))\n",
        "\n",
        "    X_trine ,y_trine = X[:tranig_split],y[:tranig_split]\n",
        "    X_test,y_test = X[tranig_split:],y[tranig_split:]\n",
        "\n",
        "    def plot_predication(trand_data = X_trine, trine_label = y_trine, test_data = X_test, test_label = y_test, predication = None):\n",
        "\n",
        "        trand_data = trand_data.detach().cpu().numpy()\n",
        "        trine_label =  trine_label.detach().cpu().numpy()\n",
        "        test_data = test_data.detach().cpu().numpy()\n",
        "        test_label = test_label.detach().cpu().numpy()\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.scatter(trand_data, trine_label, color='blue', s = 4, label='Training data')\n",
        "        plt.scatter(test_data, test_label, color='green', s = 4, label='Test data')\n",
        "        if predication is not None:\n",
        "            predication = predication.detach().cpu().numpy()\n",
        "            plt.scatter(X_test.detach().cpu().numpy(),predication.detach().cpu().numpy(),color='red',s = 4,label='Predicted data')\n",
        "            plt.title(\"Training Data and Test Data\")\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.title(\"Training Data and Test Data\")\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "    # building a model for linear regression\n",
        "    class LinearRegressionModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.weights = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
        "            self.bies = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
        "\n",
        "        # forward mahout\n",
        "        def forward(self,X : torch.Tensor) -> torch.Tensor:\n",
        "            return self.weights * X + self.bies\n",
        "\n",
        "    model = LinearRegressionModel()\n",
        "    print(model.parameters)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # plot_predication()"
      ],
      "metadata": {
        "id": "ZwWehbzLXVP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_tensor():\n",
        "    tensor_image = torch.rand(3,64,64,dtype=torch.float32)\n",
        "\n",
        "    image_numpy = tensor_image.detach().cpu().numpy()\n",
        "\n",
        "    image_numpy = image_numpy.transpose(1, 2, 0)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_numpy)\n",
        "    plt.axis('off')  # Turn off axis\n",
        "    plt.title(\"Tensor as Image\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#\n",
        "# known_parameters()\n",
        "# print(torch.randn(1))\n",
        "# pint(torch.rand(1))"
      ],
      "metadata": {
        "id": "hkOMfJgJXVS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def weight_and_bies():\n",
        "\n",
        "    x = torch.tensor([0.1], device=device)\n",
        "    y_true = torch.tensor([6.0], device=device)\n",
        "\n",
        "    w = torch.tensor([0.1], requires_grad=True, device=device)\n",
        "    b = torch.tensor([0.0], requires_grad=True, device=device)\n",
        "\n",
        "    lr = 0.1\n",
        "\n",
        "    for i in range(30):\n",
        "        y_pred = w * x + b\n",
        "        loss = (y_pred - y_true).pow(2).mean()\n",
        "        print(i, \"w=\", w.item(), \"b=\", b.item(), \"loss=\", loss.item(),'\\n')\n",
        "        print(f\"y_pred={y_pred.item()}, y_true={y_true.item()},{(y_pred - y_true).pow(2).mean().item()}\",'\\n')\n",
        "\n",
        "        loss.backward()\n",
        "        print(F\"W = {w.grad.item()},B = {b.grad.item()}\",'\\n')\n",
        "        with torch.no_grad():\n",
        "            w -= lr * w.grad\n",
        "            b -= lr * b.grad\n",
        "\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "        print(i, \"w=\", w.item(), \"b=\", b.item(), \"loss=\", loss.item(),'\\n')\n",
        "\n",
        "# weight_and_bies()\n"
      ],
      "metadata": {
        "id": "GkhzsXayXVVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}